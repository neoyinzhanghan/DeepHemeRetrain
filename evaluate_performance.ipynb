{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluting Model Performance\n",
    "- Accuracy\n",
    "- Per-class precision and recall\n",
    "- Confusion matrix\n",
    "- F1-score per class \n",
    "- Macro-averaged precision, recall and F1\n",
    "- ROC curves (one versus all) for every single class\n",
    "- Precision-recall curve for every single class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from scripts.train import model_create\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "model_checkpoint_path = \"/media/hdd1/neo/MODELS/2025-05-31 Remodelled ResNeXt DeepHemeRetrain/1/version_0/checkpoints/epoch=499-step=27500.ckpt\"\n",
    "data_path = \"/media/hdd1/neo/pooled_deepheme_data/val\"\n",
    "save_dir = \"/media/hdd1/neo/pooled_deepheme_data\"\n",
    "\n",
    "cellnames = [\n",
    "    \"B1\",\n",
    "    \"B2\",\n",
    "    \"E1\",\n",
    "    \"E4\",\n",
    "    \"ER1\",\n",
    "    \"ER2\",\n",
    "    \"ER3\",\n",
    "    \"ER4\",\n",
    "    \"ER5\",\n",
    "    \"ER6\",\n",
    "    \"L2\",\n",
    "    \"L4\",\n",
    "    \"M1\",\n",
    "    \"M2\",\n",
    "    \"M3\",\n",
    "    \"M4\",\n",
    "    \"M5\",\n",
    "    \"M6\",\n",
    "    \"MO2\",\n",
    "    \"PL2\",\n",
    "    \"PL3\",\n",
    "    \"U1\",\n",
    "    \"U4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling Data\n",
    "We start by compiling the data. The expected input is a model checkpoint path and a path to the testing or validation data folder structued in the imagenet format or whatever format renderable by the intended dataloader. We are going to compile the model's outputs using a GPU And save as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_create(path=model_checkpoint_path)\n",
    "\n",
    "\n",
    "def predict_batch(pil_images, model):\n",
    "    # Define the transformations\n",
    "    image_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(96),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply transformations to each image and create a batch\n",
    "    batch = torch.stack([image_transforms(image).float() for image in pil_images])\n",
    "\n",
    "    # Move the batch to the GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    # Set the model to evaluation mode and make predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch)\n",
    "\n",
    "        # apply softmax to the outputs\n",
    "        outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "    # Process each output as in the original code snippet\n",
    "    predictions = []\n",
    "    for output in outputs:\n",
    "        output = output.detach().cpu().numpy()\n",
    "        predictions.append(tuple(output))\n",
    "\n",
    "    # Return a list of predictions in the same order as the input images\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def predict_image(pil_image, model):\n",
    "    pil_images = [pil_image]\n",
    "\n",
    "    # Call the predict_batch function\n",
    "    predictions = predict_batch(pil_images, model)\n",
    "\n",
    "    # Return the first prediction\n",
    "    return predictions[0]\n",
    "\n",
    "\n",
    "result_df_dct = {\n",
    "    \"image_path\": [],\n",
    "    \"label\": [],\n",
    "}\n",
    "\n",
    "for cellname in cellnames:\n",
    "    result_df_dct[cellname] = []\n",
    "\n",
    "for cellname in tqdm(cellnames, desc=\"Processing cell types\"):\n",
    "    image_dir_path = os.path.join(data_path, cellname)\n",
    "\n",
    "    # find all the .jpg, .jpeg, .png files in the directory\n",
    "    image_paths = [\n",
    "        os.path.join(image_dir_path, f)\n",
    "        for f in os.listdir(image_dir_path)\n",
    "        if f.endswith(\".jpg\") or f.endswith(\".jpeg\") or f.endswith(\".png\")\n",
    "    ]\n",
    "\n",
    "    for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "        image = Image.open(image_path)\n",
    "        prediction = predict_image(image, model)\n",
    "\n",
    "        result_df_dct[\"image_path\"].append(image_path)\n",
    "        result_df_dct[\"label\"].append(cellname)\n",
    "        for i, cellname in enumerate(cellnames):\n",
    "            result_df_dct[cellname].append(prediction[i])\n",
    "\n",
    "result_df = pd.DataFrame(result_df_dct)\n",
    "\n",
    "# save the result as a csv file in the save_dir\n",
    "result_df.to_csv(os.path.join(save_dir, \"predictions.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_path = \"/Users/neo/Documents/DATA/deephemev3_val_predictions.csv\"\n",
    "\n",
    "# open the csv file as a pandas dataframe\n",
    "df = pd.read_csv(prediction_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
